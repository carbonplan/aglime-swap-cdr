# --------------------------------------------
#
# helper functions for building the batch
# input .csv files
#
# --------------------------------------------
import itertools
import os
import warnings

import pandas as pd


## [1] BUILD DATAFRAME
def build_df(
    pref: str,
    const_dict: dict,
    sites: list,
    by_site: dict,
    all_combinations: dict,
    add_ctrl: bool,
) -> pd.DataFrame:
    """
    Turn dictionaries into a .csv file that serves as a batch input for
    running SCEPTER. Vars are either constant for all runs, only vary by
    site, or vary from one run to the next (within a site).
    All dicts should be structured such that the key
    is the column name, the value is a cell value

    Parameters
    ----------
    pref : str
        prefix for each run name
    const_dict : dict
        dictionary for the values that are held constant
        across all simulations
    sites : list
        list of the site names across which to run the simulations
    by_site : dict
        dictionary for all the values that only vary by site
        (each value should be a list of len(sites) where the
        first value corresponds to the first site indexed, and
        so on)
    all_combinations : dict
        dictionary for all the values to vary such that every
        unique combination of these values is tested for each
        site
    add_ctrl : bool
        [True | False] whether to add a control simulation with zero
        dust application for each site (NOTE, you may not want to add
        0 to your dust app rate list because it will needlessly repeat
        for every other var in all_combinations)

    Returns
    -------
    pd.DataFrame
        This is the file that will become the .csv batch input. Each column
        should be a variable that the SCEPTER python scripts can recognize
        (no typos!)
    """
    # [1] generate all combinations from the dict's vectors
    all_combos_list = list(itertools.product(*all_combinations.values()))
    # make dataframe and repeat values for the number of sites
    df = pd.DataFrame(all_combos_list * len(sites), columns=all_combinations.keys())

    # [2] add site-specific vars
    # add site labels
    df["site"] = [site for site in sites for _ in range(len(all_combos_list))]
    # for each key in by_site, alternate the values for the corresponding site
    for key, values in by_site.items():
        df[key] = [
            values[site_idx]
            for site_idx in range(len(sites))
            for _ in range(len(all_combos_list))
        ]

    # [3] add constant vars
    for key, value in const_dict.items():
        df[key] = value

    # [4] add control cases (no dust application) if add_ctrl is True
    if add_ctrl:
        # loop through sites
        for thissite in reversed(sites):
            tmp_row = df[df["site"] == thissite].iloc[0]
            # set dust to zero
            tmp_row["dustrate"] = 0.0
            # concat to top row
            df = pd.concat([pd.DataFrame([tmp_row]), df], ignore_index=True)

    # [5] add the newrun ID
    df = newrun_id_fxn(df, pref, None)
    # check that all the run ids are unique and return a warning if not
    if not df["newrun_id"].is_unique:
        warnings.warn(
            "Column newrun_id contains duplicate entries. The latter run ID will likely overwrite the former"
        )

    return df


# [2] MAKE NEWRUN ID
def newrun_id_fxn(df: pd.DataFrame, pref: str, clim_tag: str) -> pd.DataFrame:
    """
    Generate an ID string for a given run based on the inputs (especially
    the application rate, duration, and dust radius -- put the dust type in
    the prefix, though note it can get added in SCEPTER py script anyway.)

    Parameters
    ----------
    df : pd.DataFrame
        dataframe generated within build_df function which has all inputs
        represented for each row.
    pref : str
        prefix for the run (this will often include the dust type; e.g., 'gbas')
        it can be None, but that's not recommended
    clim_tag : str
        the tag for the years of climate model output used (e.g., '1950-2020').
        If no climate model data is used, set this to None

    Returns
    -------
    pd.DataFrame
        This is the file that will become the .csv batch input. Each column
        should be a variable that the SCEPTER python scripts can recognize
        (no typos!)
    """
    # create empty column
    df["newrun_id"] = None
    # loop through each row
    for index, row in df.iterrows():
        # assign the dust flux if it exists
        dstflx = (
            "app_" + str(row["dustrate"]).replace(".", "p")
            if "dustrate" in row
            else None
        )
        # assign the particle size if it exists
        psize = (
            "psize_" + str(row["dustrad"]).replace(".", "p")
            if "dustrad" in row
            else None
        )

        # pull out other vars
        site = row["climatefiles"]
        dur = (
            "tau_" + str(row["duration"]).replace(".", "p")
            if "duration" in row
            else None
        )
        # (not using dur for now because the python script in SCEPTER repo adds it in itself)

        # create the new ID
        this_id = "_".join(
            [s for s in [pref, site, clim_tag, dstflx, psize] if s is not None]
        )

        # add it to the pandas df
        df.at[index, "newrun_id"] = this_id

    # return result
    return df


# [3] SAVE DATAFRAME AS CSV
def save_df(
    df: pd.DataFrame,
    savepath_batch: str,
    fn: str,
    multi_run_split: bool,
    max_iters_per_set: int = None,
):
    """
    Save the pandas DataFrame as a .csv file to use for batch inputs
    for SCEPTER. If you're filename already exists, the function will
    warn you and ask if you want to proceed with overwriting it.

    Parameters
    ----------
    df : pd.DataFrame
        dataframe generated within build_df function which has all inputs
        represented for each row.
    savepath_batch : str
        path to the directory where you want to save the output csv files
    fn : str
        filename of the .csv file we want to save (if we split into multiple,
        this is the core name that holds it all together)
    multi_run_split : bool
        T/F; whether or not to split the df into multiple CSV files
    max_iters_per_set : int
        if multi_run_split is true, then how many iters should we allow per
        csv file (default is None, assuming multi_run_split is False)

    Returns
    -------

    """
    if multi_run_split:
        # calculate the number of chunks needed
        num_chunks = -(-len(df) // max_iters_per_set)  # round up the division result
        # splitting df into chunks of approximately 20 rows each
        dfs = [
            df.iloc[i * max_iters_per_set : (i + 1) * max_iters_per_set]
            for i in range(num_chunks)
        ]
        # saving each df to a different file
        for i, df_chunk in enumerate(dfs):
            tot_dfs = len(dfs)
            savefn_nosuff = fn.rstrip(".csv")
            savefn_out = f"{savefn_nosuff}_set{i + 1}of{tot_dfs}.csv"
            # print(os.path.join(savepath_batch, savefn_out))
            savepath = os.path.join(savepath_batch, savefn_out)
            # save and prevent accidentally overwriting another file
            prevent_accidental_overwrite(df_chunk, savepath, savefn_out)
        # also save total
        savepath_all = os.path.join(savepath_batch, fn)
        prevent_accidental_overwrite(df, savepath_all, fn)
    else:
        savepath_all = os.path.join(savepath_batch, fn)
        prevent_accidental_overwrite(df, savepath_all, fn)


# FUNCTION check if a file already exists
def prevent_accidental_overwrite(df: pd.DataFrame, path_fn: str, fn: str):
    """
    This function is used within the save_df function to check that we're
    not going to accidentally overwrite another file upon save. If we are,
    we ask the user to give permission to proceed.

    Parameters
    ----------
    df : pd.DataFrame
        dataframe generated within build_df function which has all inputs
        represented for each row.
    path_fn : str
        full path with filename of the file we want to save (but haven't yet)
        (ex: "/this/is/my/path/to/file.csv")
    fn : str
        just the name of the file
        (ex: "file.csv")

    Returns
    -------

    """
    # check if the file already exists at this path
    if os.path.exists(path_fn):
        # ask the user whether they want to continue / overwrite the file
        response = (
            input(
                f"A file with this name already exists ({fn}). Do you want to overwrite it? (Y/N): "
            )
            .strip()
            .upper()
        )
        if response == "N":
            warnings.warn("File save canceled to prevent overwrite")
            return
        elif response != "Y":
            warnings.warn("Invalid response. File save canceled.")
            return
        else:
            df.to_csv(path_fn, index=False)
            print("Thanks for your response, the file was saved.")
    # if it doesn't exist, allow the save to happen
    else:
        df.to_csv(path_fn, index=False)
        print("File successfully saved")
