{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1136834c-202b-480a-8989-9f59a7249701",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Script to generate plots from spinup run\n",
    "import glob\n",
    "import os\n",
    "import re\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# --- set figure-generating parameters\n",
    "runs2save = \"all\"  # (later, build functionality for this to be a list)\n",
    "domain = [\"field\"]  # [\"field, \"lab\"] or just one\n",
    "prof_list = [\n",
    "    \"prof_aq\",\n",
    "    \"prof_aq(ads%cec)\",\n",
    "    \"prof_gas\",\n",
    "    \"prof_sld(wt%)\",\n",
    "    \"sa\",\n",
    "    \"rate\",\n",
    "]  # \"bsd\"...\n",
    "flx_list = [\"flx_co2sp\", \"flx_gas\", \"flx_aq\", \"flx_sld\"]\n",
    "flx_plot_excludezeros = True  # True means we don't render lines that contribute no flux the entire timeseries\n",
    "logtime_color = [\n",
    "    True,\n",
    "    False,\n",
    "]  # [True, False] or just one; whether to make time colorbar a log scale\n",
    "\n",
    "# --- where to save\n",
    "save_base = \"/home/tykukla/aglime-swap-cdr/scepter/process/spinups/figures\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "45c818e1-5515-4755-8210-3d69c5ffc47f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- plotting decisions\n",
    "# ***** PROFILE PLOTS ******\n",
    "num_cols = 3  # number of columns for multipanel\n",
    "varmax_threshold = (\n",
    "    1e-6  # concentrations smaller than this won't get zoomed in on (effectively zero)\n",
    ")\n",
    "xax_titlesize = 20\n",
    "yax_titlesize = 13\n",
    "xticksize = 14\n",
    "yticksize = 12\n",
    "cbar_titlesize = 15\n",
    "cbar_ticksize = 10\n",
    "\n",
    "# ***** FLUX PLOTS ******\n",
    "Fnum_cols = 3  # number of columns for multipanel\n",
    "Fxax_titlesize = 20\n",
    "Fyax_titlesize = 13\n",
    "Fxticksize = 14\n",
    "Fyticksize = 12\n",
    "Fcbar_titlesize = 15\n",
    "Fcbar_ticksize = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4850878c-0619-4e9a-96ad-ddc917cde46d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>site</th>\n",
       "      <th>spinname</th>\n",
       "      <th>lat</th>\n",
       "      <th>lon</th>\n",
       "      <th>mat</th>\n",
       "      <th>soilmoisture</th>\n",
       "      <th>qrun</th>\n",
       "      <th>tsom</th>\n",
       "      <th>erosion</th>\n",
       "      <th>nitrif</th>\n",
       "      <th>tph</th>\n",
       "      <th>cec</th>\n",
       "      <th>tec</th>\n",
       "      <th>tsoilco2</th>\n",
       "      <th>poro</th>\n",
       "      <th>alpha</th>\n",
       "      <th>spinname_full</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>site_311</td>\n",
       "      <td>site_311</td>\n",
       "      <td>42.5</td>\n",
       "      <td>-91</td>\n",
       "      <td>8.22219</td>\n",
       "      <td>0.282727</td>\n",
       "      <td>0.351361</td>\n",
       "      <td>2.051667</td>\n",
       "      <td>0.001013</td>\n",
       "      <td>1.005952</td>\n",
       "      <td>6.058007</td>\n",
       "      <td>21.10329</td>\n",
       "      <td>20.98031</td>\n",
       "      <td>-1.80371</td>\n",
       "      <td>0.447</td>\n",
       "      <td>2.0</td>\n",
       "      <td>site_311_spintuneup</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>site_411</td>\n",
       "      <td>site_411</td>\n",
       "      <td>32.0</td>\n",
       "      <td>-83</td>\n",
       "      <td>18.52789</td>\n",
       "      <td>0.231552</td>\n",
       "      <td>0.243426</td>\n",
       "      <td>2.276667</td>\n",
       "      <td>0.000840</td>\n",
       "      <td>0.831883</td>\n",
       "      <td>5.200242</td>\n",
       "      <td>1.96125</td>\n",
       "      <td>46.91557</td>\n",
       "      <td>-1.61194</td>\n",
       "      <td>0.419</td>\n",
       "      <td>2.0</td>\n",
       "      <td>site_411_spintuneup</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       site  spinname   lat  lon       mat  soilmoisture      qrun      tsom  \\\n",
       "0  site_311  site_311  42.5  -91   8.22219      0.282727  0.351361  2.051667   \n",
       "1  site_411  site_411  32.0  -83  18.52789      0.231552  0.243426  2.276667   \n",
       "\n",
       "    erosion    nitrif       tph       cec       tec  tsoilco2   poro  alpha  \\\n",
       "0  0.001013  1.005952  6.058007  21.10329  20.98031  -1.80371  0.447    2.0   \n",
       "1  0.000840  0.831883  5.200242   1.96125  46.91557  -1.61194  0.419    2.0   \n",
       "\n",
       "         spinname_full  \n",
       "0  site_311_spintuneup  \n",
       "1  site_411_spintuneup  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# --- read in spinup table\n",
    "csv_fn = \"spinup-inputs.csv\"\n",
    "csv_loc = \"/home/tykukla/aglime-swap-cdr/scepter/batch-inputs\"\n",
    "dfin = pd.read_csv(os.path.join(csv_loc, csv_fn))\n",
    "\n",
    "# add column for fullname (minus field / lab)\n",
    "dfin[\"spinname_full\"] = dfin[\"spinname\"] + \"_spintuneup\"\n",
    "\n",
    "dfin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5a74abd1-0d75-4e2c-a14b-624076ad2df2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- FUNCTION to preprocess .txt files for consistent delimiters\n",
    "\n",
    "\n",
    "def preprocess_txt(file_path):\n",
    "    data = []  # Initialize a list to store the processed data\n",
    "\n",
    "    # Initialize a flag to determine if we are reading the header\n",
    "    is_header = True\n",
    "\n",
    "    # Read the file line by line and process the data\n",
    "    with open(file_path) as file:\n",
    "        for line in file:\n",
    "            line = line.strip()  # Remove leading/trailing whitespace\n",
    "            if is_header:\n",
    "                # Split the first line into column names\n",
    "                column_names = re.split(r\"\\s+\", line)\n",
    "                is_header = False\n",
    "            else:\n",
    "                # Split the other lines into data values\n",
    "                values = re.split(r\"\\s+\", line)\n",
    "                data.append(values)\n",
    "\n",
    "    # Create a DataFrame with the processed data and set column names\n",
    "    df = pd.DataFrame(data, columns=column_names)\n",
    "    # return\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8ffd0abe-2a74-4748-b12c-a67b88caddd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- function to read in profile data\n",
    "\n",
    "\n",
    "def read_prof_dat(resdir, runname_in, domain_in, prof_list):\n",
    "    # where results are stored\n",
    "    dirname = runname_in + \"_\" + domain_in\n",
    "    results_path = os.path.join(resdir, dirname)\n",
    "    prof_path = os.path.join(results_path, \"prof\")\n",
    "\n",
    "    # define file name pattern\n",
    "    fn_pref = prof_list\n",
    "    fn_ext = \".txt\"\n",
    "\n",
    "    # loop through variables\n",
    "    df = pd.DataFrame()  # initialize empty df to store dat\n",
    "    for var in fn_pref:\n",
    "        # read out status\n",
    "        print(\"reading in \" + var + \"...\")\n",
    "        # set pattern\n",
    "        fn_pattern = f\"{var}-*{fn_ext}\"\n",
    "        # get list of filenames\n",
    "        file_paths = glob.glob(f\"{prof_path}/{fn_pattern}\")\n",
    "\n",
    "        # read in data and concatenate\n",
    "        for file_path in file_paths:\n",
    "            dfi = preprocess_txt(file_path)\n",
    "            # apply pd.to_numeric to all columns using the \"map\" method\n",
    "            dfi = dfi.map(pd.to_numeric)\n",
    "            # add var\n",
    "            dfi[\"var\"] = var\n",
    "            # combine\n",
    "            df = pd.concat([df, dfi], ignore_index=True)\n",
    "\n",
    "    # sort by time and depth\n",
    "    df = df.sort_values(by=[\"var\", \"time\", \"z\"])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "23d0e7ec-9f71-4b43-9bf6-fb3a33bc2369",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- function to read in flux data\n",
    "def read_flx_dat(resdir, runname_in, domain_in, flx_list):\n",
    "    # where results are stored\n",
    "    dirname = runname_in + \"_\" + domain_in\n",
    "    results_path = os.path.join(resdir, dirname)\n",
    "    flx_path = os.path.join(results_path, \"flx\")\n",
    "\n",
    "    # define file name pattern\n",
    "    fn_pref = flx_list\n",
    "    fn_varInclude = []\n",
    "    varCheck = True if len(fn_varInclude) > 0 else False\n",
    "    fn_ext = \".txt\"\n",
    "\n",
    "    df = pd.DataFrame()  # initialize empty df to store dat\n",
    "\n",
    "    for fset in fn_pref:\n",
    "        # read out status\n",
    "        print(\"reading in \" + fset + \"...\")\n",
    "        # set pattern\n",
    "        fn_pattern = f\"{fset}-*{fn_ext}\"\n",
    "        # get list of filenames\n",
    "        file_paths = glob.glob(f\"{flx_path}/{fn_pattern}\")\n",
    "\n",
    "        # read in data and concatenate\n",
    "        for file_path in file_paths:\n",
    "            # get the variable\n",
    "            varpattern = re.escape(fset) + r\"-(.*?).txt\"\n",
    "            varmatch = re.search(varpattern, file_path)\n",
    "            var = varmatch.group(1)\n",
    "            # skip this step if it's not in the include arr\n",
    "            if varCheck:\n",
    "                if var not in fn_varInclude:\n",
    "                    continue\n",
    "            # read in\n",
    "            dfi = preprocess_txt(file_path)\n",
    "            # apply pd.to_numeric to all columns using the \"map\" method\n",
    "            dfi = dfi.map(pd.to_numeric)\n",
    "            # add set, var, spinrun, ctrl\n",
    "            dfi[\"set\"] = fset\n",
    "            dfi[\"var\"] = var\n",
    "\n",
    "            # combine\n",
    "            df = pd.concat([df, dfi], ignore_index=True)\n",
    "\n",
    "    # drop all time slices dangerously close to zero (these produce astronomical (like 10^10 or higher) residuals)\n",
    "    # df = df.loc[df['time'] > 1e-3]\n",
    "\n",
    "    # sort by time and depth\n",
    "    df = df.sort_values(by=[\"set\", \"var\", \"time\"])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "43b66ab4-3be7-495b-959a-da2e99d149ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_profile(\n",
    "    df,\n",
    "    tdf,\n",
    "    save_base,\n",
    "    domain_in,\n",
    "    logtime_color,\n",
    "    num_cols=3,\n",
    "    xax_titlesize=20,\n",
    "    yax_titlesize=13,\n",
    "    xticksize=14,\n",
    "    yticksize=12,\n",
    "    cbar_titlesize=15,\n",
    "    cbar_ticksize=10,\n",
    "    save_dpi=250,\n",
    "    save_transparent=False,\n",
    "    plot_prefix=\"PROF_\",\n",
    "):\n",
    "\n",
    "    # --- turn off interactive mode\n",
    "    plt.ioff()\n",
    "\n",
    "    # --- set the output directory\n",
    "    save_prof_dir = os.path.join(save_base, tdf[\"site\"], domain_in)\n",
    "    # create it if it doesn't exist\n",
    "    if not os.path.exists(save_prof_dir):\n",
    "        os.makedirs(save_prof_dir)\n",
    "\n",
    "    # --- get list of variables to loop through\n",
    "    thesevars = df[\"var\"].unique()\n",
    "\n",
    "    # LOOP ONE --- VARS\n",
    "    for thisvar in thesevars:\n",
    "        # extract just the variable we want\n",
    "        dfx = df[df[\"var\"] == thisvar]\n",
    "        # remove columns with all nan\n",
    "        dfx1 = dfx.dropna(axis=1, how=\"all\")\n",
    "        # remove columns whose names are numbers\n",
    "        number_pattern = re.compile(\n",
    "            r\"^[-+]?\\d*\\.?\\d+(?:[eE][-+]?\\d+)?$\"\n",
    "        )  # required to detect columns that are numbers\n",
    "        for col in dfx1.columns:\n",
    "            if number_pattern.match(col):\n",
    "                dfx1.drop(columns=col, inplace=True)\n",
    "        # set the plot df\n",
    "        dfp = dfx1\n",
    "\n",
    "        # LOOP 2 --- WHETHER COLOR BAR IS A LOG SCALE\n",
    "        for log_col in logtime_color:\n",
    "            # Get the list of variables\n",
    "            variables = [col for col in dfp.columns if col not in [\"z\", \"time\", \"var\"]]\n",
    "\n",
    "            # group by time\n",
    "            grouped = dfp.groupby(\"time\")\n",
    "\n",
    "            # Calculate number of rows and columns for subplots\n",
    "            num_rows = -(-len(variables) // num_cols)  # Round up division\n",
    "\n",
    "            # Create a colormap\n",
    "            cmap = plt.get_cmap(\"magma\")  # Get the colormap\n",
    "            cmap = cmap.reversed()  # flip colormap\n",
    "            # -- no log normalization\n",
    "            if not log_col:\n",
    "                norm = plt.Normalize(\n",
    "                    df[\"time\"].min(), df[\"time\"].max()\n",
    "                )  # Normalize time values for colormap\n",
    "            # -- log normalization WIP\n",
    "            else:\n",
    "                log_time = np.log(df[\"time\"])\n",
    "                norm = plt.Normalize(\n",
    "                    log_time.min(), log_time.max()\n",
    "                )  # Normalize time values for colormap\n",
    "\n",
    "            # Create a colorbar based on the Viridis colormap\n",
    "            sm = plt.cm.ScalarMappable(cmap=cmap, norm=norm)\n",
    "\n",
    "            # Create subplots\n",
    "            fig, axes = plt.subplots(\n",
    "                num_rows, num_cols, figsize=(5 * num_cols, 4 * num_rows)\n",
    "            )\n",
    "\n",
    "            # Plot each variable versus depth\n",
    "            for i, var in enumerate(variables):\n",
    "                row = i // num_cols\n",
    "                col = i % num_cols\n",
    "                ax = axes[row, col] if num_rows > 1 else axes[col]\n",
    "                # get max (to determine how to handle y-axis)\n",
    "                varmax = np.nanmax(dfp[var])\n",
    "\n",
    "                # Create a plot for each time step\n",
    "                for time, group in grouped:\n",
    "                    color = cmap(norm(time))  # Map time to color using Viridis colormap\n",
    "                    ax.plot(\n",
    "                        group[var], group[\"z\"], color=color, label=None, linewidth=3\n",
    "                    )\n",
    "                ax.set_ylabel(\"Depth\", size=yax_titlesize)\n",
    "                ax.set_xlabel(var, size=xax_titlesize)\n",
    "                ax.tick_params(\n",
    "                    axis=\"x\", which=\"major\", labelsize=xticksize\n",
    "                )  # Adjust the size as needed\n",
    "                ax.tick_params(\n",
    "                    axis=\"y\", which=\"major\", labelsize=yticksize\n",
    "                )  # Adjust the size as needed\n",
    "                # set limits if needed\n",
    "                if varmax < varmax_threshold:\n",
    "                    ax.set_xlim(0, varmax_threshold)\n",
    "                ax.invert_yaxis()\n",
    "\n",
    "            # Remove empty subplots\n",
    "            for i in range(len(variables), num_rows * num_cols):\n",
    "                row = i // num_cols\n",
    "                col = i % num_cols\n",
    "                fig.delaxes(axes[row, col] if num_rows > 1 else axes[col])\n",
    "\n",
    "            # add colorbar\n",
    "            sm.set_array([])  # Set an empty array for the colorbar data\n",
    "            if log_col:\n",
    "                colorlabel = \"logTime (yr)\"\n",
    "                cbar = plt.colorbar(sm, label=colorlabel, ax=plt.gca())\n",
    "            else:\n",
    "                colorlabel = \"Time (yr)\"\n",
    "                cbar = plt.colorbar(sm, label=colorlabel, ax=plt.gca())\n",
    "            cbar.set_label(colorlabel, fontsize=cbar_titlesize)\n",
    "            cbar.ax.tick_params(labelsize=cbar_ticksize)\n",
    "\n",
    "            plt.tight_layout()\n",
    "            # plt.show()\n",
    "\n",
    "            # --- save the result\n",
    "            if log_col:\n",
    "                fname = plot_prefix + thisvar + \"_logColor.png\"\n",
    "            else:\n",
    "                fname = plot_prefix + thisvar + \".png\"\n",
    "            plt.savefig(\n",
    "                os.path.join(save_prof_dir, fname),\n",
    "                dpi=250,\n",
    "                bbox_inches=\"tight\",\n",
    "                transparent=save_transparent,\n",
    "            )\n",
    "            # --- close to release memory\n",
    "            plt.close()\n",
    "\n",
    "    # --- turn interactive mode back on\n",
    "    plt.ion()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7ae25705-2141-48f5-a981-49ca6631fe75",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_flx(\n",
    "    df,\n",
    "    tdf,\n",
    "    save_base,\n",
    "    domain_in,\n",
    "    mycmap=\"magma\",\n",
    "    color_start=0.1,\n",
    "    color_end=0.9,\n",
    "    Fnum_cols=3,\n",
    "    Fxax_titlesize=20,\n",
    "    Fyax_titlesize=13,\n",
    "    Fxticksize=14,\n",
    "    Fyticksize=12,\n",
    "    save_dpi=250,\n",
    "    save_transparent=False,\n",
    "    plot_prefix=\"FLUX_\",\n",
    "):\n",
    "    # --- turn interactive mode off\n",
    "    plt.ioff()\n",
    "    # --- set the output directory\n",
    "    save_prof_dir = os.path.join(save_base, tdf[\"site\"], domain_in)\n",
    "    # create it if it doesn't exist\n",
    "    if not os.path.exists(save_prof_dir):\n",
    "        os.makedirs(save_prof_dir)\n",
    "\n",
    "    # --- get list of variables to loop through\n",
    "    thesesets = df[\"set\"].unique()\n",
    "\n",
    "    # --- LOOP 1: THIS SET\n",
    "    for thisset in thesesets:\n",
    "        dfset = df[df[\"set\"] == thisset]\n",
    "\n",
    "        # --- get a color dictionary\n",
    "        if flx_plot_excludezeros:  # remove columns with all zeros\n",
    "            dftmp = dfset.loc[:, (dfset != 0).any(axis=0)]\n",
    "        allflux_components = [\n",
    "            col for col in dftmp.columns if col not in [\"set\", \"time\", \"var\"]\n",
    "        ]\n",
    "        cmap = plt.get_cmap(mycmap)\n",
    "        num_colors = len(allflux_components)\n",
    "        colors = cmap(np.linspace(color_start, color_end, num_colors))\n",
    "        color_dict = dict(zip(allflux_components, colors))\n",
    "\n",
    "        # --- get vars\n",
    "        thesevars = dfset[\"var\"].unique()\n",
    "\n",
    "        # --- Calculate number of rows and columns for subplots\n",
    "        num_rows = -(-len(thesevars) // Fnum_cols)  # Round up division\n",
    "        # count which panel we're on\n",
    "        cnt = 0\n",
    "\n",
    "        # --- Create subplots\n",
    "        fig, axes = plt.subplots(\n",
    "            num_rows, Fnum_cols, figsize=(5 * Fnum_cols, 4 * num_rows)\n",
    "        )\n",
    "\n",
    "        # --- LOOP 2: THESEVARS\n",
    "        for thisvar in thesevars:\n",
    "            # extract just the variable we want\n",
    "            dfx = dfset[dfset[\"var\"] == thisvar]\n",
    "            # remove columns with all nan\n",
    "            dfx1 = dfx.dropna(axis=1, how=\"all\")\n",
    "            # remove columns with all zeros\n",
    "            if flx_plot_excludezeros:\n",
    "                dfx2 = dfx1.loc[:, (dfx1 != 0).any(axis=0)]\n",
    "            else:\n",
    "                dfx2 = dfx1\n",
    "            # remove columns whose names are numbers\n",
    "            number_pattern = re.compile(\n",
    "                r\"^[-+]?\\d*\\.?\\d+(?:[eE][-+]?\\d+)?$\"\n",
    "            )  # required to detect columns that are numbers\n",
    "            for col in dfx2.columns:\n",
    "                if number_pattern.match(col):\n",
    "                    dfx2.drop(columns=col, inplace=True)\n",
    "            # set the plot df\n",
    "            dfp = dfx2\n",
    "\n",
    "            # Get the list of variables\n",
    "            variables = [\n",
    "                col for col in dfp.columns if col not in [\"set\", \"time\", \"var\"]\n",
    "            ]\n",
    "\n",
    "            # Plot each variable versus time\n",
    "            row = cnt // Fnum_cols\n",
    "            col = cnt % Fnum_cols\n",
    "\n",
    "            for i, var in enumerate(variables):\n",
    "                ax = axes[row, col] if num_rows > 1 else axes[col]\n",
    "                if i % 2 == 0:\n",
    "                    linestylex = \"--\"  # if even,\n",
    "                else:\n",
    "                    linestylex = \"solid\"\n",
    "                ax.plot(\n",
    "                    dfp[\"time\"],\n",
    "                    dfp[var],\n",
    "                    color=color_dict[var],\n",
    "                    label=var,\n",
    "                    linewidth=3,\n",
    "                    linestyle=linestylex,\n",
    "                )\n",
    "\n",
    "            ax.set_title(thisvar)\n",
    "            ax.set_ylabel(\"flux\", size=Fyax_titlesize)\n",
    "            ax.set_xlabel(\"Time (yr)\", size=Fxax_titlesize)\n",
    "            ax.tick_params(\n",
    "                axis=\"x\", which=\"major\", labelsize=Fxticksize\n",
    "            )  # Adjust the size as needed\n",
    "            ax.tick_params(\n",
    "                axis=\"y\", which=\"major\", labelsize=Fyticksize\n",
    "            )  # Adjust the size as needed\n",
    "            ax.legend()\n",
    "\n",
    "            # update cnt\n",
    "            cnt += 1\n",
    "\n",
    "        # Remove empty subplots\n",
    "        for i in range(len(variables), num_rows * Fnum_cols):\n",
    "            row = i // Fnum_cols\n",
    "            col = i % Fnum_cols\n",
    "            fig.delaxes(axes[row, col] if num_rows > 1 else axes[col])\n",
    "\n",
    "        # add colorbar\n",
    "        plt.tight_layout()\n",
    "        # plt.show()\n",
    "\n",
    "        # --- save the result\n",
    "        fname = plot_prefix + thisset + \".png\"\n",
    "        plt.savefig(\n",
    "            os.path.join(save_prof_dir, fname),\n",
    "            dpi=250,\n",
    "            bbox_inches=\"tight\",\n",
    "            transparent=save_transparent,\n",
    "        )\n",
    "        # --- close to release memory\n",
    "        plt.close()\n",
    "\n",
    "    # --- turn interactive mode back on\n",
    "    plt.ion()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "93ce9218-910e-437f-9291-d99abb5bd0bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reading in prof_aq...\n",
      "reading in prof_aq(ads%cec)...\n",
      "reading in prof_gas...\n",
      "reading in prof_sld(wt%)...\n",
      "reading in sa...\n",
      "reading in rate...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_115546/3886520615.py:28: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dfx1.drop(columns=col, inplace=True)\n",
      "/tmp/ipykernel_115546/3886520615.py:28: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dfx1.drop(columns=col, inplace=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reading in flx_co2sp...\n",
      "reading in flx_gas...\n",
      "reading in flx_aq...\n",
      "reading in flx_sld...\n",
      "reading in prof_aq...\n",
      "reading in prof_aq(ads%cec)...\n",
      "reading in prof_gas...\n",
      "reading in prof_sld(wt%)...\n",
      "reading in sa...\n",
      "reading in rate...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_115546/3886520615.py:28: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dfx1.drop(columns=col, inplace=True)\n",
      "/tmp/ipykernel_115546/3886520615.py:28: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dfx1.drop(columns=col, inplace=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reading in flx_co2sp...\n",
      "reading in flx_gas...\n",
      "reading in flx_aq...\n",
      "reading in flx_sld...\n"
     ]
    }
   ],
   "source": [
    "# --- run the loop and generate figures\n",
    "resdir = \"/home/tykukla/SCEPTER/scepter_output\"  # location of output directories\n",
    "\n",
    "# select which runs to use\n",
    "if runs2save == \"all\":\n",
    "    dfin = dfin\n",
    "# ELSE... select all the spinnames from a list\n",
    "\n",
    "# LOOP -------------------------------------------------------\n",
    "# --- first across all runs\n",
    "for trun in range(len(dfin)):\n",
    "    runname_in = dfin[\"spinname_full\"][trun]\n",
    "    tdf = dfin.loc[trun]\n",
    "\n",
    "    # --- second across lab / field domains\n",
    "    for domain_in in domain:\n",
    "        # ***** PROFILE DATA ***** #\n",
    "        # read in\n",
    "        df = read_prof_dat(resdir, runname_in, domain_in, prof_list)\n",
    "        # plot + save ----------------------------------------------------\n",
    "        plot_profile(df, tdf, save_base, domain_in, logtime_color)\n",
    "        # ----------------------------------------------------------------\n",
    "\n",
    "        # ***** FLUX DATA ***** #\n",
    "        # read in\n",
    "        df_flx = read_flx_dat(resdir, runname_in, domain_in, flx_list)\n",
    "        # plot + save ----------------------------------------------------\n",
    "        plot_flx(df_flx, tdf, save_base, domain_in)\n",
    "        # ----------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "db2a47ec-3b35-4197-91c5-e08219eb7829",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'site_311_spintuneup'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df_flx\n",
    "tdf = dfin.loc[0]\n",
    "runname_in = dfin[\"spinname_full\"][0]\n",
    "domain_in = domain[0]\n",
    "runname_in"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "global-global-carbonplan",
   "language": "python",
   "name": "conda-env-global-global-carbonplan-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
